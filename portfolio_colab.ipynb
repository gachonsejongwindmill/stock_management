{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "위에서부터 끝까지 아래로 순서대로 작동시키면 됩니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "KfDEaozwPGhP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31a2aaa0",
        "outputId": "f3021ec1-14d8-413b-c2ea-43e7929411eb"
      },
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start ollama in the background\n",
        "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# Give ollama time to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Verify ollama is running\n",
        "try:\n",
        "    subprocess.run([\"ollama\", \"list\"], check=True, capture_output=True, text=True)\n",
        "    print(\"Ollama is running.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error starting Ollama: {e}\")\n",
        "    print(f\"Stdout: {e.stdout}\")\n",
        "    print(f\"Stderr: {e.stderr}\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "Ollama is running.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaebd823",
        "outputId": "e742917b-f59f-460b-da02-5a4a88639911"
      },
      "source": [
        "!ollama pull gemma3:12b\n",
        "!ollama pull gemma3:latest\n",
        "!ollama list"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "NAME             ID              SIZE      MODIFIED               \n",
            "gemma3:latest    a2af6cc3eb7f    3.3 GB    Less than a second ago    \n",
            "gemma3:12b       f4031aab637d    8.1 GB    40 seconds ago            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef386573",
        "outputId": "2108ec13-699c-450a-db6d-3d6eaee9c3aa"
      },
      "source": [
        "!pip install ollama"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ollama\n",
            "  Downloading ollama-0.5.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.12/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.12/dist-packages (from ollama) (2.11.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
            "Downloading ollama-0.5.3-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ollama\n",
            "Successfully installed ollama-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O \"plots_sp500.zip\" \"https://drive.google.com/uc?export=download&id=1xbqffWc0thSrWvKPp7T_oCbBiWR2tzE6\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7ptP549MC1L",
        "outputId": "40dc5a2d-abe2-4724-f368-2ce659b0e064"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-20 15:59:04--  https://drive.google.com/uc?export=download&id=1xbqffWc0thSrWvKPp7T_oCbBiWR2tzE6\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.137.102, 74.125.137.138, 74.125.137.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.137.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1xbqffWc0thSrWvKPp7T_oCbBiWR2tzE6&export=download [following]\n",
            "--2025-08-20 15:59:04--  https://drive.usercontent.google.com/download?id=1xbqffWc0thSrWvKPp7T_oCbBiWR2tzE6&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.101.132, 2607:f8b0:4023:c06::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.101.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169460 (165K) [application/octet-stream]\n",
            "Saving to: ‘plots_sp500.zip’\n",
            "\n",
            "plots_sp500.zip     100%[===================>] 165.49K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-08-20 15:59:07 (3.66 MB/s) - ‘plots_sp500.zip’ saved [169460/169460]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -a plots_sp500.zip -d ./plots_sp500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZJ6vS5QL1cP",
        "outputId": "782ebafd-d91c-46a5-b4d6-a224d75b7ffa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  plots_sp500.zip\n",
            "  inflating: ./plots_sp500/A_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AAPL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ABBV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ABNB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ABT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ACGL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ACN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ADBE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ADI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ADM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ADP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ADSK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AEE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AEP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AES_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AFL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AIG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AIZ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AJG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AKAM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ALB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ALGN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ALL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ALLE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AMAT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AMCR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AMD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AME_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AMGN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AMP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AMT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AMZN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ANET_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AON_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AOS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/APA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/APD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/APH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/APO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/APTV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ARE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ATO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AVB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AVGO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AVY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AWK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AXON_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AXP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/AZO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BAC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BALL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BAX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BBY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BDX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BEN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BIIB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BKNG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BKR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BLDR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BLK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BMY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BRO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BSX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/BXP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/C_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CAG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CAH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CARR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CAT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CBOE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CBRE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CCI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CCL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CDNS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CDW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CEG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CF_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CFG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CHD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CHRW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CHTR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CINF_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CLX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CMCSA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CME_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CMG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CMI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CMS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CNC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CNP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/COF_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/COIN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/COO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/COP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/COR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/COST_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CPAY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CPB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CPRT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CPT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CRL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CRM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CRWD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CSCO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CSGP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CSX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CTAS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CTRA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CTSH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CTVA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CVS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CVX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/CZR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/D_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DAL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DASH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DAY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DDOG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DECK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DELL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DGX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DHI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DHR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DIS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DLR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DLTR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DOC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DOV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DOW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DPZ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DRI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DTE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DUK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DVA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DVN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/DXCM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EBAY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ECL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ED_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EFX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EIX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ELV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EMN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EMR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ENPH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EOG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EPAM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EQIX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EQR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EQT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ERIE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ES_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ESS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ETN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ETR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EVRG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EXC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EXE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EXPD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EXPE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/EXR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/F_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FANG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FAST_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FCX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FDS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FDX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FFIV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FICO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FIS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FITB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FOX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FOXA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FRT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FSLR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FTNT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/FTV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GDDY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GEHC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GEN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GILD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GIS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GLW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GNRC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GOOG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GOOGL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GPC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GPN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GRMN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/GWW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HAL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HAS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HBAN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HCA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HIG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HII_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HLT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HOLX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HON_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HPE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HPQ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HRL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HSIC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HST_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HSY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HUBB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HUM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/HWM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IBM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ICE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IDXX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IEX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IFF_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/INCY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/INTC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/INTU_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/INVH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IPG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IQV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IRM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ISRG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ITW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/IVZ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/J_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/JBHT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/JBL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/JCI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/JKHY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/JNJ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/JPM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/K_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KDP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KEY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KEYS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KHC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KIM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KKR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KLAC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KMB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KMI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KMX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/KVUE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/L_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LDOS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LEN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LHX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LII_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LIN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LKQ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LLY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LMT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LNT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LOW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LRCX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LULU_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LUV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LVS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LYB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/LYV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MAA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MAR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MAS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MCD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MCHP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MCK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MCO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MDLZ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MDT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MET_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/META_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MGM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MHK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MKC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MKTX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MLM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MMC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MMM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MNST_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MOH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MOS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MPC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MPWR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MRK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MRNA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MSCI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MSFT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MSI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MTB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MTCH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MTD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/MU_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NCLH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NDAQ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NDSN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NEE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NEM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NFLX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NKE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NOC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NOW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NRG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NSC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NTAP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NTRS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NUE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NVDA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NVR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NWS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NWSA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/NXPI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/O_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ODFL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/OKE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/OMC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ON_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ORCL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ORLY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/OTIS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/OXY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PANW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PARA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PAYC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PAYX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PCAR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PCG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PEG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PEP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PFE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PFG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PGR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PHM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PKG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PLD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PLTR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PNC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PNR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PNW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PODD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/POOL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PPG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PPL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PRU_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PSA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PSKY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PSX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PTC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PWR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/PYPL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/QCOM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/RCL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/REG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/REGN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/RF_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/RJF_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/RL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/RMD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ROK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ROL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ROP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ROST_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/RSG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/RTX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/RVTY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SBAC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SBUX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SCHW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SHW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SJM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SLB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SMCI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SNA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SNPS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SPG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SPGI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SRE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/STE_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/STLD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/STT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/STX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/STZ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SWK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SWKS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SYF_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SYK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/SYY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/T_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TAP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TDG_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TDY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TECH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TEL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TER_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TFC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TGT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TJX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TKO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TMO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TMUS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TPL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TPR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TRGP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TRMB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TROW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TRV_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TSCO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TSLA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TSN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TTD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TTWO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TXN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TXT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/TYL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/UAL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/UBER_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/UDR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/UHS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ULTA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/UNH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/UNP_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/UPS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/URI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/USB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/V_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VICI_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VLO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VLTO_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VMC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VRSK_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VRSN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VRTX_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VST_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VTR_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VTRS_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/VZ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WAB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WAT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WBA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WBD_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WDAY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WDC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WEC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WELL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WFC_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WMB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WMT_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WRB_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WSM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WST_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WTW_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WY_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/WYNN_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/XEL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/XOM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/XYL_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/XYZ_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/YUM_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ZBH_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ZBRA_forecast.csv  [binary]\n",
            "  inflating: ./plots_sp500/ZTS_forecast.csv  [binary]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "import time\n",
        "import re\n",
        "import sys\n",
        "import subprocess\n",
        "import json\n",
        "import builtins\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    __file__ = '/content/portfolio_colab.ipynb'\n",
        "\n",
        "class PrintLogger:\n",
        "    def __init__(self, logger):\n",
        "        self.logger = logger\n",
        "        self.original_print = builtins.print\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        self.logger.info(' '.join(map(str, args)))\n",
        "        self.original_print(*args, **kwargs)\n",
        "\n",
        "def setup_logging():\n",
        "    log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'logs')\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    log_file = os.path.join(log_dir, f'portfolio_maker_{timestamp}.log')\n",
        "\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file, encoding='utf-8'),\n",
        "            logging.StreamHandler()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    print_logger = PrintLogger(logger)\n",
        "    builtins.print = print_logger\n",
        "\n",
        "    logger.info(f\"Logging initialized. Log file: {log_file}\")\n",
        "    return logger\n",
        "\n",
        "logger = setup_logging()\n",
        "def setup_data_loading() -> Tuple[str, List[str]]:\n",
        "    \"\"\"Setup and verify data loading configuration.\"\"\"\n",
        "    logger.info(\"Starting data loading setup\")\n",
        "\n",
        "    folder_path = \"./plots_sp500\"\n",
        "    logger.info(f\"Looking for forecast files in: {folder_path}\")\n",
        "\n",
        "    csv_files = glob(os.path.join(folder_path, \"*_forecast.csv\"))\n",
        "\n",
        "    if not csv_files:\n",
        "        error_msg = f\"No forecast files found in {folder_path}\"\n",
        "        logger.error(error_msg)\n",
        "        raise FileNotFoundError(error_msg)\n",
        "\n",
        "    logger.info(f\"Found {len(csv_files)} forecast files\")\n",
        "    return folder_path, csv_files\n",
        "\n",
        "def load_forecast_data(csv_files: List[str]) -> List[pd.DataFrame]:\n",
        "    \"\"\"Load forecast data from CSV files.\"\"\"\n",
        "    logger.info(\"Starting to load forecast data\")\n",
        "    dfs = []\n",
        "\n",
        "    for idx, file_path in enumerate(csv_files, 1):\n",
        "        try:\n",
        "            filename = os.path.basename(file_path)\n",
        "            symbol = filename.replace(\"_forecast.csv\", \"\")\n",
        "            logger.debug(f\"[{idx}/{len(csv_files)}] Processing {filename}, symbol: {symbol}\")\n",
        "\n",
        "            logger.debug(f\"Reading CSV: {file_path}\")\n",
        "            df = pd.read_csv(file_path, usecols=[\"Date\", \"Predicted\"])\n",
        "\n",
        "            if df.empty:\n",
        "                logger.warning(f\"Empty DataFrame for {symbol}, skipping...\")\n",
        "                continue\n",
        "\n",
        "            if 'Date' not in df.columns or 'Predicted' not in df.columns:\n",
        "                logger.error(f\"Required columns not found in {filename}\")\n",
        "                continue\n",
        "\n",
        "            df.rename(columns={\"Predicted\": symbol}, inplace=True)\n",
        "\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df = df.sort_values('Date')\n",
        "\n",
        "            df = df.drop_duplicates(subset=['Date'], keep='last')\n",
        "\n",
        "            dfs.append(df)\n",
        "            logger.debug(f\"Successfully loaded {len(df)} rows for {symbol}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing {file_path}: {str(e)}\", exc_info=True)\n",
        "            continue\n",
        "\n",
        "    if not dfs:\n",
        "        error_msg = \"No valid forecast data was loaded\"\n",
        "        logger.error(error_msg)\n",
        "        raise ValueError(error_msg)\n",
        "\n",
        "    logger.info(f\"Successfully loaded {len(dfs)} out of {len(csv_files)} forecast files\")\n",
        "    return dfs\n",
        "\n",
        "def merge_forecast_data(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
        "    \"\"\"Merge multiple forecast DataFrames on the 'Date' column.\"\"\"\n",
        "    logger.info(\"Starting to merge forecast data\")\n",
        "\n",
        "    if not dfs:\n",
        "        error_msg = \"No DataFrames to merge\"\n",
        "        logger.error(error_msg)\n",
        "        raise ValueError(error_msg)\n",
        "\n",
        "    try:\n",
        "        logger.debug(f\"Merging {len(dfs)} DataFrames\")\n",
        "        from functools import reduce\n",
        "        merged_df = reduce(lambda left, right: pd.merge(left, right, on='Date', how='outer'), dfs)\n",
        "\n",
        "        logger.debug(\"Sorting by date\")\n",
        "        merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
        "        merged_df = merged_df.sort_values('Date')\n",
        "\n",
        "        merged_df = merged_df.drop_duplicates(subset=['Date'], keep='last')\n",
        "\n",
        "        logger.info(f\"Merged DataFrame shape: {merged_df.shape}\")\n",
        "        logger.debug(f\"Date range: {merged_df['Date'].min()} to {merged_df['Date'].max()}\")\n",
        "        logger.debug(f\"Columns: {', '.join([col for col in merged_df.columns if col != 'Date'])}\")\n",
        "\n",
        "        return merged_df\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error merging DataFrames: {str(e)}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        logger.info(\"=== Starting Portfolio Maker ===\")\n",
        "\n",
        "        folder_path, csv_files = setup_data_loading()\n",
        "        dfs = load_forecast_data(csv_files)\n",
        "        merged_df = merge_forecast_data(dfs)\n",
        "\n",
        "        logger.info(\"Data loading and merging completed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Fatal error in Portfolio Maker: {str(e)}\", exc_info=True)\n",
        "        raise\n",
        "    merged_df_2 = merged_df.copy()\n",
        "    merged_df_2.iloc[:, 1:] = merged_df_2.iloc[:, 1:].pct_change()\n",
        "    merged_df_2.dropna(inplace=True)\n",
        "    std_series = merged_df_2.iloc[:, 1:].std()\n",
        "\n",
        "    def classify_risk(std):\n",
        "        if std >= 0.2:\n",
        "            return \"Very High Risk\"\n",
        "        elif 0.1 <= std < 0.2:\n",
        "            return \"High Risk\"\n",
        "        elif 0.06 <= std < 0.1:\n",
        "            return \"Medium Risk\"\n",
        "        elif 0.01 <= std < 0.06:\n",
        "            return \"Low Risk\"\n",
        "        else:\n",
        "            return \"Very Low Risk\"\n",
        "\n",
        "    risk_levels = std_series.apply(classify_risk)\n",
        "\n",
        "\n",
        "    price_df = merged_df.iloc[:, 1:]\n",
        "\n",
        "    first_prices = price_df.iloc[0]\n",
        "\n",
        "    max_prices = price_df.max()\n",
        "    min_prices = price_df.min()\n",
        "    change_rates = ((max_prices - first_prices) / first_prices).round(4)\n",
        "    change_rates2 = ((min_prices - first_prices) / first_prices).round(4)\n",
        "\n",
        "    risk_df = risk_levels.reset_index()\n",
        "    risk_df.columns = ['Stock', 'RiskLevel']\n",
        "\n",
        "    change_df = pd.DataFrame({\n",
        "        'Stock': change_rates.index,\n",
        "        'Risk_Levels' : risk_df['RiskLevel'].values,\n",
        "        'Max_ChangeRate': change_rates.values,\n",
        "        'Min_ChangeRate': change_rates2.values\n",
        "    })\n",
        "\n",
        "\n",
        "    import subprocess\n",
        "    import json\n",
        "\n",
        "    def chat_with_gemma(message: str,temperature: float = 0.0) -> str:\n",
        "        import requests\n",
        "\n",
        "        url = \"http://localhost:11434/api/generate\"\n",
        "        payload = {\n",
        "            \"model\": \"gemma3:12b\",\n",
        "            \"prompt\": message,\n",
        "            \"stream\": False,\n",
        "            \"temperature\": temperature\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, json=payload)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            return data.get(\"response\", \"\").strip()\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error in chat_with_gemma (HTTP request failed): {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def get_news_cache_file() -> str:\n",
        "        cache_dir = os.path.join(os.path.dirname(__file__), 'news_cache')\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "        today = datetime.now().strftime('%Y-%m-%d')\n",
        "        return os.path.join(cache_dir, f'news_cache_{today}.csv')\n",
        "\n",
        "    def load_cached_news() -> Dict[str, List[Dict]]:\n",
        "        cache_file = get_news_cache_file()\n",
        "        if not os.path.exists(cache_file):\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(cache_file)\n",
        "            df['articles'] = df['articles'].apply(eval)\n",
        "            return df.set_index('symbol')['articles'].to_dict()\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load news cache: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def save_news_to_cache(symbol: str, articles: List[Dict]):\n",
        "        try:\n",
        "            cache_file = get_news_cache_file()\n",
        "\n",
        "            if os.path.exists(cache_file):\n",
        "                df = pd.read_csv(cache_file)\n",
        "                mask = df['symbol'] == symbol\n",
        "                if mask.any():\n",
        "                    df.loc[mask, 'articles'] = str(articles)\n",
        "                else:\n",
        "                    df = pd.concat([df, pd.DataFrame([{'symbol': symbol, 'articles': str(articles)}])],\n",
        "                                ignore_index=True)\n",
        "            else:\n",
        "                df = pd.DataFrame([{'symbol': symbol, 'articles': str(articles)}])\n",
        "\n",
        "            df.to_csv(cache_file, index=False)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not save news cache: {str(e)}\")\n",
        "\n",
        "    def get_stock_news(symbol: str, use_cache: bool = True, api_key: str = \"afd7dddd5a0e4c13b8f504529f664e48\") -> List[Dict]:\n",
        "        if use_cache:\n",
        "            cached_news = load_cached_news()\n",
        "            if symbol in cached_news:\n",
        "                print(f\"   - {symbol} (from cache)\", end='', flush=True)\n",
        "                return cached_news[symbol]\n",
        "\n",
        "        try:\n",
        "            print(f\"\\n   - {symbol} (fetching news...)\", end='', flush=True)\n",
        "\n",
        "            to_date = datetime.now()\n",
        "            from_date = to_date - timedelta(days=7)\n",
        "\n",
        "            to_date_str = to_date.strftime('%Y-%m-%d')\n",
        "            from_date_str = from_date.strftime('%Y-%m-%d')\n",
        "\n",
        "            url = f\"https://newsapi.org/v2/everything?q={symbol} stock&from={from_date_str}&to={to_date_str}&language=en&sortBy=publishedAt&apiKey={api_key}\"\n",
        "            print(f\"\\n   - API URL: {url.split('&apiKey=')[0]}...\")\n",
        "\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            data = response.json()\n",
        "\n",
        "            print(f\"   - API Response Status: {response.status_code}\")\n",
        "            print(f\"   - Total Results: {data.get('totalResults', 0)}\")\n",
        "\n",
        "            if 'status' in data and data['status'] == 'error':\n",
        "                print(f\"   - API Error: {data.get('message', 'Unknown error')}\")\n",
        "                return []\n",
        "\n",
        "            articles = data.get('articles', [])[:5]\n",
        "\n",
        "            if not articles:\n",
        "                print(f\"   - No articles found for {symbol}\")\n",
        "                return []\n",
        "\n",
        "            print(f\"   - Found {len(articles)} articles for {symbol}\")\n",
        "\n",
        "            save_news_to_cache(symbol, articles)\n",
        "\n",
        "            return articles\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"\\nRequest failed for {symbol}:\")\n",
        "            print(f\"   - Error Type: {type(e).__name__}\")\n",
        "            print(f\"   - Error Details: {str(e)}\")\n",
        "            if hasattr(e, 'response') and e.response is not None:\n",
        "                print(f\"   - Status Code: {e.response.status_code}\")\n",
        "                try:\n",
        "                    error_data = e.response.json()\n",
        "                    print(f\"   - Error Message: {error_data.get('message', 'No error message')}\")\n",
        "                    print(f\"   - Error Code: {error_data.get('code', 'N/A')}\")\n",
        "                except:\n",
        "                    print(f\"   - Response Text: {e.response.text[:200]}...\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nUnexpected error for {symbol}:\")\n",
        "            print(f\"   - Error Type: {type(e).__name__}\")\n",
        "            print(f\"   - Error Details: {str(e)}\")\n",
        "\n",
        "        return []\n",
        "\n",
        "    def analyze_news_sentiment(articles: List[Dict]) -> Dict:\n",
        "        if not articles:\n",
        "            return {\"sentiment\": \"neutral\", \"summary\": \"No recent news articles found.\"}\n",
        "\n",
        "        texts = [f\"{article.get('title', '')}. {article.get('description', '')}\"\n",
        "                for article in articles]\n",
        "\n",
        "        combined_text = \"\\n\".join(texts)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Analyze the sentiment of the following news articles about a company.\n",
        "        Consider the overall tone (positive/negative/neutral) and provide a brief summary.\n",
        "\n",
        "        News Articles:\n",
        "        {combined_text}\n",
        "        Return a JSON object in the following format:\n",
        "        answer: [\n",
        "        {{\n",
        "            \"sentiment\": \"positive\",\n",
        "            \"summary\": \"The company reported strong quarterly earnings and announced new product launches.\",\n",
        "            \"impact\": \"positive\"\n",
        "        }}\n",
        "        ]\n",
        "\n",
        "        Make sure your answer follows the same JSON structure exactly, replacing the example values with the analysis based on the news articles.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = chat_with_gemma(prompt)\n",
        "            match = re.search(r'answer:\\s*(\\[\\s*\\{.*?\\}\\s*\\])', response, re.DOTALL)\n",
        "            if match:\n",
        "                data = json.loads(match.group(1))\n",
        "                return data\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing news sentiment: {str(e)}\")\n",
        "\n",
        "        return {\"sentiment\": \"neutral\", \"summary\": \"Could not analyze sentiment.\", \"impact\": \"neutral\"}\n",
        "\n",
        "    def split_stock_table(stock_table, max_tokens=4000):\n",
        "        chunk_size = max_tokens * 2\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "\n",
        "        lines = stock_table.strip().split('\\n')\n",
        "\n",
        "        for line in lines:\n",
        "            line_length = len(line) + 1  # +1 for newline\n",
        "            if current_length + line_length > chunk_size and current_chunk:\n",
        "                chunks.append('\\n'.join(current_chunk))\n",
        "                current_chunk = []\n",
        "                current_length = 0\n",
        "            current_chunk.append(line)\n",
        "            current_length += line_length\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append('\\n'.join(current_chunk))\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def analyze_stock_chunk(chunk, user_age, loss_tolerance_percent, chunk_num, total_chunks):\n",
        "        analysis_prompt = f\"\"\"\n",
        "        You are a financial analyst. Analyze the following stock data and identify the most promising candidates for a diversified portfolio.\n",
        "\n",
        "        User profile:\n",
        "        - Age: {user_age}\n",
        "        - Loss tolerance: {loss_tolerance_percent}% of total assets\n",
        "\n",
        "        This is chunk {chunk_num} of {total_chunks}.\n",
        "\n",
        "        Stock data (S&P 500 stocks):\n",
        "        {chunk}\n",
        "\n",
        "        For each stock, consider:\n",
        "        1. Risk level (Very High to Very Low)\n",
        "        2. Predicted 21-day return\n",
        "        3. Diversification across sectors\n",
        "\n",
        "        Return a list of 3-5 stock symbols with brief reasoning for each selection.\n",
        "        Focus on stocks with the best risk-return profile for the user's risk tolerance.\n",
        "\n",
        "        Format your response with one stock symbol per line, optionally followed by a colon and reasoning.\n",
        "        Example:\n",
        "        AAPL: Strong fundamentals and growth potential\n",
        "        GOOGL: Dominant in cloud computing\n",
        "\n",
        "        Important: Only include the stock symbols and optional reasoning, nothing else.\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"Analyzing chunk {chunk_num} of {total_chunks}...\")\n",
        "        return chat_with_gemma(analysis_prompt)\n",
        "    def extract_final_symbols(response_text):\n",
        "\n",
        "        match = re.search(r'answer:\\s*(\\[\\s*\\{.*?\\}\\s*\\])', response_text, re.DOTALL)\n",
        "        if match:\n",
        "            try:\n",
        "                final_stocks = json.loads(match.group(1))\n",
        "                symbols = [stock.get(\"symbol\") for stock in final_stocks if \"symbol\" in stock]\n",
        "                if symbols:\n",
        "                    return symbols\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"JSON 파싱 실패, fallback으로 텍스트 분석 시도\")\n",
        "\n",
        "        symbols = []\n",
        "        for line in response_text.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            if ':' in line:\n",
        "                symbol = line.split(':')[0].strip()\n",
        "            elif len(line) <= 5:\n",
        "                symbol = line\n",
        "            else:\n",
        "                continue\n",
        "            if symbol and symbol not in symbols:\n",
        "                symbols.append(symbol)\n",
        "\n",
        "        return symbols\n",
        "    def analyze_stocks(stock_table, user_age, loss_tolerance_percent):\n",
        "\n",
        "        chunks = split_stock_table(stock_table)\n",
        "\n",
        "        if len(chunks) == 1:\n",
        "\n",
        "            print(\"Analyzing stocks to select top candidates...\")\n",
        "            initial_analysis = analyze_stock_chunk(chunks[0], user_age, loss_tolerance_percent, 1, 1)\n",
        "        else:\n",
        "\n",
        "            print(f\"Processing {len(chunks)} chunks of stock data...\")\n",
        "            chunk_results = []\n",
        "            for i, chunk in enumerate(chunks, 1):\n",
        "                result = analyze_stock_chunk(chunk, user_age, loss_tolerance_percent, i, len(chunks))\n",
        "                chunk_results.append(result)\n",
        "                time.sleep(1)\n",
        "\n",
        "\n",
        "            initial_analysis = '\\n'.join(chunk_results)\n",
        "\n",
        "        print(\"Initial stock analysis complete. Selected symbols:\")\n",
        "\n",
        "\n",
        "\n",
        "        lines = [line.strip() for line in initial_analysis.split('\\n') if line.strip()]\n",
        "        top_symbols = []\n",
        "\n",
        "        for line in lines:\n",
        "\n",
        "            if ':' in line:\n",
        "                symbol = line.split(':')[0].strip().replace('-', '').strip()\n",
        "                if symbol and len(symbol) <= 5:\n",
        "                    top_symbols.append(symbol)\n",
        "                    print(f\"   - {symbol}: {line.split(':', 1)[1].strip() if ':' in line else ''}\")\n",
        "            elif len(line.split()) == 1 and 1 <= len(line) <= 5:\n",
        "                top_symbols.append(line.strip())\n",
        "                print(f\"   - {line.strip()}\")\n",
        "\n",
        "\n",
        "        top_symbols = list(dict.fromkeys(top_symbols))[:10]\n",
        "        print(f\"Fetching news for {len(top_symbols)} top stocks...\")\n",
        "\n",
        "        stock_news = {}\n",
        "\n",
        "\n",
        "        cached_news = load_cached_news()\n",
        "\n",
        "        for symbol in top_symbols:\n",
        "            try:\n",
        "\n",
        "                if symbol in cached_news and cached_news[symbol]:\n",
        "                    articles = cached_news[symbol]\n",
        "                    print(f\"   - {symbol} (from cache)\", end='')\n",
        "                    from_cache = True\n",
        "                else:\n",
        "\n",
        "                    print(f\"   - {symbol} (fetching...)\", end='')\n",
        "                    articles = get_stock_news(symbol, use_cache=False)\n",
        "                    from_cache = False\n",
        "\n",
        "                if articles:\n",
        "                    if not from_cache:\n",
        "                        print(f\" ✓ Found {len(articles)} articles\")\n",
        "\n",
        "\n",
        "                    print(f\"   - Analyzing sentiment for {symbol}...\", end='')\n",
        "                    sentiment = analyze_news_sentiment(articles)\n",
        "                    print(f\" {sentiment['sentiment'].upper()}\")\n",
        "\n",
        "                    stock_news[symbol] = {\n",
        "                        'articles': [{'title': a.get('title', ''), 'url': a.get('url', '')} for a in articles],\n",
        "                        'sentiment': sentiment\n",
        "                    }\n",
        "\n",
        "\n",
        "                    if articles and 'title' in articles[0]:\n",
        "                        print(f\"     Sample: {articles[0].get('title', 'No title')}\")\n",
        "                else:\n",
        "                    print(f\"   - {symbol}: No articles found\")\n",
        "                    stock_news[symbol] = {\n",
        "                        'articles': [],\n",
        "                        'sentiment': {'sentiment': 'neutral', 'summary': 'No recent news found.'}\n",
        "                    }\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {symbol}: {str(e)}\")\n",
        "                stock_news[symbol] = {\n",
        "                    'articles': [],\n",
        "                    'sentiment': {'sentiment': 'error', 'summary': f'Error: {str(e)}'}\n",
        "                }\n",
        "\n",
        "            print()\n",
        "            time.sleep(1)\n",
        "\n",
        "        print(\"News Collection Summary:\")\n",
        "        for symbol, data in stock_news.items():\n",
        "            article_count = len(data.get('articles', []))\n",
        "            sentiment = data.get('sentiment', {}).get('sentiment', 'unknown').upper()\n",
        "            print(f\"   - {symbol}: {article_count} articles, {sentiment} sentiment\")\n",
        "\n",
        "        final_analysis_prompt = f\"\"\"\n",
        "        Based on the initial stock analysis and recent news sentiment, refine the stock selection.\n",
        "\n",
        "        Initial Analysis:\n",
        "        {initial_analysis}\n",
        "\n",
        "        Recent News Analysis:\n",
        "        {json.dumps(stock_news, indent=2)}\n",
        "\n",
        "        Update your stock recommendations considering both the financial metrics and news sentiment.\n",
        "        Return a JSON object in the following format:\n",
        "\n",
        "        answer: [\n",
        "        {{\n",
        "            \"symbol\": \"AAPL\",\n",
        "            \"reason\": \"Strong fundamentals and positive news sentiment\"\n",
        "        }},\n",
        "        {{\n",
        "            \"symbol\": \"MSFT\",\n",
        "            \"reason\": \"Strong fundamentals and positive news sentiment\"\n",
        "        }}\n",
        "        ]\n",
        "\n",
        "        Make sure to return 5-10 stock objects, each with \"symbol\" and \"reason\" keys.\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Analyzing news sentiment and refining stock selection...\")\n",
        "        final_analysis = chat_with_gemma(final_analysis_prompt)\n",
        "\n",
        "        final_symbols = extract_final_symbols(final_analysis)\n",
        "\n",
        "        final_stock_news = {k: v for k, v in stock_news.items() if k in final_symbols}\n",
        "\n",
        "        for symbol in final_symbols:\n",
        "            if symbol not in final_stock_news:\n",
        "                final_stock_news[symbol] = {\n",
        "                    'articles': [],\n",
        "                    'sentiment': {'sentiment': 'neutral', 'summary': 'No recent news found.'}\n",
        "                }\n",
        "\n",
        "        return final_stock_news\n",
        "\n",
        "    def create_portfolio(analysis_results, user_context, attempt):\n",
        "        allocation_prompt = f\"\"\"\n",
        "        Based on the following analysis and user context, create an optimal portfolio allocation.\n",
        "\n",
        "        User context:\n",
        "        - Age: {user_context['age']}\n",
        "        - Risk tolerance: {user_context['risk_tolerance']}%\n",
        "        - Investment horizon: {user_context.get('horizon', 'medium-term')}\n",
        "\n",
        "        Analysis results (including news sentiment):\n",
        "        {analysis_results}\n",
        "\n",
        "        Please provide a portfolio with 5 stocks that balances risk and return, considering both financial metrics and recent news sentiment.\n",
        "\n",
        "        Guidelines:\n",
        "        0. Only use stocks that are in the S&P500.\n",
        "        1. Favor stocks with positive news sentiment and strong fundamentals.\n",
        "        2. Be cautious with stocks that have negative news, even if their financials look good.\n",
        "        3. Ensure proper diversification across sectors.\n",
        "        4. Adjust sector and stock risk levels according to the user's age and risk tolerance:\n",
        "        - Younger investors with higher risk tolerance may have more growth-oriented allocations.\n",
        "        - Older investors or those with lower risk tolerance should prioritize stability and income.\n",
        "        5. Ensure the overall portfolio risk profile aligns with the user's risk tolerance percentage.\n",
        "        6. Include exactly 5 stocks in the portfolio.\n",
        "        7. Return the portfolio in this exact JSON format:\n",
        "        {{\n",
        "            \"stocks\": [\"SYM1\", \"SYM2\", \"SYM3\", \"SYM4\", \"SYM5\"],\n",
        "            \"allocation\": [0.3, 0.25, 0.2, 0.15, 0.1],\n",
        "            \"reasoning\": \"Brief explanation including how news sentiment influenced the allocation\",\n",
        "            \"risk_analysis\": \"Brief assessment of the overall portfolio risk profile\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "        return chat_with_gemma(allocation_prompt, attempt*0.1)\n",
        "\n",
        "    def validate_stocks_exist(recommended_stocks, available_stocks):\n",
        "        missing = [s for s in recommended_stocks if s not in available_stocks]\n",
        "        if missing:\n",
        "            print(f\"Warning: The following stocks are not in our data: {', '.join(missing)}\")\n",
        "        return not missing\n",
        "\n",
        "    import re\n",
        "    import json\n",
        "\n",
        "    def parse_portfolio_response(response_str, max_retries=1):\n",
        "        last_error = None\n",
        "\n",
        "        for attempt in range(max_retries + 1):\n",
        "            try:\n",
        "                match = re.search(r'\\{[^{}]*\\}', response_str, re.DOTALL)\n",
        "                if match:\n",
        "                    json_str = match.group(0)\n",
        "                    portfolio = json.loads(json_str)\n",
        "\n",
        "                    if \"stocks\" in portfolio and isinstance(portfolio[\"stocks\"], list):\n",
        "                        portfolio[\"stocks\"] = [\n",
        "                            s.strip().upper() for s in portfolio[\"stocks\"] if isinstance(s, str)\n",
        "                        ]\n",
        "\n",
        "                    if not all(key in portfolio for key in ['stocks', 'allocation', 'reasoning']):\n",
        "                        raise ValueError(\"Missing required fields in portfolio response\")\n",
        "\n",
        "                    if len(portfolio['stocks']) != 5 or len(portfolio['allocation']) != 5:\n",
        "                        raise ValueError(\"Portfolio must contain exactly 5 stocks\")\n",
        "\n",
        "                    if not all(isinstance(x, (int, float)) for x in portfolio['allocation']):\n",
        "                        raise ValueError(\"Allocation values must be numbers\")\n",
        "\n",
        "                    if abs(sum(portfolio['allocation']) - 1.0) > 0.01:\n",
        "                        total = sum(portfolio['allocation'])\n",
        "                        portfolio['allocation'] = [round(x/total, 4) for x in portfolio['allocation']]\n",
        "\n",
        "                    return portfolio\n",
        "\n",
        "            except (json.JSONDecodeError, ValueError) as e:\n",
        "                last_error = e\n",
        "                if attempt < max_retries:\n",
        "                    print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"Warning: Could not parse JSON response: {e}\")\n",
        "                    return 1004\n",
        "\n",
        "            try:\n",
        "                match = re.search(r'\\{.*\\}', response_str, re.DOTALL)\n",
        "                if match:\n",
        "                    dict_str = match.group(0)\n",
        "                    parsed = eval(dict_str, {\"__builtins__\": None}, {})\n",
        "                    if isinstance(parsed, dict):\n",
        "                        stocks = [s.strip().upper() for s in parsed.keys()]\n",
        "                        allocations = list(parsed.values())\n",
        "                        return {\n",
        "                            'stocks': stocks,\n",
        "                            'allocation': allocations,\n",
        "                            'reasoning': 'Generated from legacy format'\n",
        "                        }\n",
        "            except Exception as e:\n",
        "                last_error = e\n",
        "                if attempt < max_retries:\n",
        "                    print(f\"Attempt {attempt + 1} failed in legacy parsing: {e}. Retrying...\")\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"Warning: Could not parse legacy format: {e}\")\n",
        "                    return 1004\n",
        "\n",
        "\n",
        "    def get_portfolio_with_retry(analysis_results, user_context, max_attempts=5):\n",
        "        \"\"\"Get portfolio with retry logic if recommended stocks are not found.\"\"\"\n",
        "        available_stocks = set(change_df['Stock'].tolist())\n",
        "        for attempt in range(1, max_attempts + 1):\n",
        "            print(f\"Portfolio Generation Attempt {attempt}/{max_attempts}\")\n",
        "\n",
        "            portfolio_response = create_portfolio(analysis_results, user_context,attempt)\n",
        "            print(\"Portfolio recommendation received.\")\n",
        "\n",
        "            try:\n",
        "                portfolio = parse_portfolio_response(portfolio_response)\n",
        "                if portfolio == 1004:\n",
        "                    raise Exception(\"양식 불합격\")\n",
        "                if validate_stocks_exist(portfolio['stocks'], available_stocks):\n",
        "                    return portfolio_response\n",
        "\n",
        "                print(f\"Some recommended stocks are not available. \"\n",
        "                    f\"Retrying with different stocks... (Attempt {attempt}/{max_attempts})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing portfolio: {str(e)}\")\n",
        "                if attempt == max_attempts:\n",
        "                    print(\"Max retry attempts reached. Using best available portfolio.\")\n",
        "                    return portfolio_response\n",
        "\n",
        "        print(\"Failed to generate a valid portfolio after multiple attempts.\")\n",
        "        return None\n",
        "\n",
        "    user_context = {\n",
        "        'age': 26,\n",
        "        'risk_tolerance': 75,\n",
        "        'horizon': 'long-term',\n",
        "        'news_api_key': 'afd7dddd5a0e4c13b8f504529f664e48'\n",
        "    }\n",
        "\n",
        "    stock_table = change_df.to_string(index=False)\n",
        "\n",
        "    print(\"Analyzing stock data...\")\n",
        "    analysis_results = analyze_stocks(stock_table, user_context['age'], user_context['risk_tolerance'])\n",
        "    print(\"Analysis complete. Creating portfolio...\")\n",
        "\n",
        "    portfolio_response = get_portfolio_with_retry(analysis_results, user_context)\n",
        "\n",
        "    if portfolio_response is None:\n",
        "        print(\"Could not generate a valid portfolio. Please try again or check your data.\")\n",
        "        exit(1)\n",
        "\n",
        "\n",
        "    portfolio = parse_portfolio_response(portfolio_response)\n",
        "    print(\"Recommended Portfolio:\")\n",
        "    for stock, weight in zip(portfolio['stocks'], portfolio['allocation']):\n",
        "        print(f\"{stock}: {weight*100:.1f}%\")\n",
        "\n",
        "    print(f\"Strategy: {portfolio['reasoning']}\")\n",
        "\n",
        "    result = dict(zip(portfolio['stocks'], portfolio['allocation']))\n",
        "\n",
        "    stock_store = []\n",
        "    valid_stocks = []\n",
        "\n",
        "    for stock, weight in result.items():\n",
        "        try:\n",
        "            if stock not in merged_df.columns:\n",
        "                print(f\"Warning: {stock} not found in data. This should not happen with the retry mechanism!\")\n",
        "                continue\n",
        "\n",
        "            max_price = merged_df[stock].max()\n",
        "            std_return = std_series[stock]\n",
        "\n",
        "            result[stock] = [round(weight, 4), round(max_price, 2), round(std_return, 4)]\n",
        "            stock_store.append(stock)\n",
        "            valid_stocks.append(stock)\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"Error processing {stock}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    if not valid_stocks:\n",
        "        print(\"Error: No valid stocks were found in the data.\")\n",
        "        exit(1)\n",
        "\n",
        "\n",
        "    result = {k: v for k, v in result.items() if k in valid_stocks}\n",
        "    result2= {}\n",
        "    for stock in merged_df.columns:\n",
        "        if stock == 'Date':\n",
        "            continue\n",
        "\n",
        "        stock_data = [\n",
        "            {\"y\": round(value, 2), \"ds\": str(date)}\n",
        "            for date, value in zip(merged_df[\"Date\"], merged_df[stock])\n",
        "            if pd.notna(value)\n",
        "        ]\n",
        "\n",
        "        result2[stock] = stock_data\n",
        "    result2 = {k: v for k, v in result2.items() if k in stock_store}\n",
        "\n",
        "    def make_result3_invest(result, result2, selected_stocks=None, initial=100):\n",
        "        if selected_stocks is None:\n",
        "            selected_stocks = list(result.keys())\n",
        "\n",
        "        weights = {s: float(result[s][0]) for s in selected_stocks if s in result}\n",
        "        total_w = sum(weights.values())\n",
        "        print(total_w)\n",
        "        if total_w == 0:\n",
        "            n = len(weights)\n",
        "            weights = {s: 1.0/n for s in weights}\n",
        "        else:\n",
        "            weights = {s: w/total_w for s,w in weights.items()}\n",
        "\n",
        "        price_map = {}\n",
        "        first_date_of_stock = {}\n",
        "        for s in selected_stocks:\n",
        "            entries = result2.get(s, [])\n",
        "            date_price = {}\n",
        "            for e in entries:\n",
        "                ds = e[\"ds\"]\n",
        "                price = float(e[\"y\"])\n",
        "                date_price[ds] = price\n",
        "            if date_price:\n",
        "                sorted_dates = sorted(date_price.keys())\n",
        "                first_date_of_stock[s] = sorted_dates[0]\n",
        "                price_map[s] = {d: date_price[d] for d in sorted_dates}\n",
        "\n",
        "        shares = {}\n",
        "        for s, ratio in weights.items():\n",
        "            if s not in price_map:\n",
        "                shares[s] = 0.0\n",
        "                continue\n",
        "            buy_date = first_date_of_stock[s]\n",
        "            buy_price = price_map[s].get(buy_date)\n",
        "            if not buy_price or buy_price == 0:\n",
        "                shares[s] = 0.0\n",
        "            else:\n",
        "                allocation = initial * ratio\n",
        "                shares[s] = allocation / buy_price\n",
        "\n",
        "        all_dates = set()\n",
        "        for s, pm in price_map.items():\n",
        "            all_dates.update(pm.keys())\n",
        "        sorted_all_dates = sorted(all_dates)\n",
        "\n",
        "        last_known_price = {s: None for s in price_map}\n",
        "        result3 = []\n",
        "        for ds in sorted_all_dates:\n",
        "            total_value = 0.0\n",
        "            for s in price_map:\n",
        "                if ds in price_map[s]:\n",
        "                    last_known_price[s] = price_map[s][ds]\n",
        "                price_for_day = last_known_price[s]\n",
        "                if price_for_day is None:\n",
        "                    continue\n",
        "                total_value += shares.get(s, 0.0) * price_for_day\n",
        "\n",
        "            result3.append({\"y\": round(total_value, 5), \"ds\": ds})\n",
        "        return result3\n",
        "\n",
        "    result3 = make_result3_invest(result,result2)\n",
        "    portfolio_reasoning = portfolio['reasoning']\n",
        "    translation_prompt = f\"\"\"\n",
        "    Translate the following investment analysis to Korean.\n",
        "\n",
        "    **Instructions:**\n",
        "    1. Maintain a professional and clear tone.\n",
        "    2. Keep the financial terms and stock symbols in English.\n",
        "    3. **Crucially: Do not write any introductory text, explanations, or summaries. The output must begin directly with the Korean translation and contain nothing else.**\n",
        "\n",
        "    **Text to translate:**\n",
        "    {portfolio_reasoning}\n",
        "    \"\"\"\n",
        "\n",
        "    ollama_api_url = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "    ollama_payload = {\n",
        "        \"model\": \"gemma3:latest\",\n",
        "        \"prompt\": translation_prompt.strip(),\n",
        "        \"stream\": False\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            ollama_api_url,\n",
        "            headers={\"Content-Type\": \"application/json\"},\n",
        "            data=json.dumps(ollama_payload)\n",
        "        )\n",
        "\n",
        "        response.raise_for_status()\n",
        "        response.encoding = 'utf-8'\n",
        "        response_data = response.json()\n",
        "\n",
        "        result4 = response_data.get('response', '번역 결과를 가져오지 못했습니다.').strip()\n",
        "\n",
        "\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        error_message = f\"Ollama API 연결에 실패했습니다: {str(e)}\"\n",
        "        print(error_message)\n",
        "        result4 = portfolio_reasoning\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"번역 중 알 수 없는 에러가 발생했습니다: {str(e)}\"\n",
        "        print(error_message)\n",
        "        result4 = portfolio_reasoning\n",
        "    print(json.dumps({\"result\": result, \"result2\": result2,\"result3\":result3,\"result4\":result4}, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbPO1mMiK1gN",
        "outputId": "1b71bb05-b53c-4d31-84cb-5f2f7841927c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing stock data...\n",
            "Processing 4 chunks of stock data...\n",
            "Analyzing chunk 1 of 4...\n",
            "Analyzing chunk 2 of 4...\n",
            "Analyzing chunk 3 of 4...\n",
            "Analyzing chunk 4 of 4...\n",
            "Initial stock analysis complete. Selected symbols:\n",
            "   - SYK: Very low risk, stable performer.\n",
            "   - WM: Very low risk, essential business.\n",
            "   - ETN: Low risk, consistent dividend payer.\n",
            "   - MDLZ: Low risk, consumer staples sector.\n",
            "   - AIG: Very low risk, financial sector stability.\n",
            "   - GOOG: Low risk with a decent predicted return.\n",
            "   - MSFT: Low risk and generally stable performer.\n",
            "   - HII: Low risk and positive predicted return.\n",
            "   - ABT: Low risk with a generally positive outlook.\n",
            "   - NWS: Low risk and consistent performance.\n",
            "   - KO: Low risk, consistent performer, essential consumer product.\n",
            "   - IR: Low risk, strong financials, dividend stock.\n",
            "   - ROP: Low risk, diversified business model, stable returns.\n",
            "   - HSIC: Low risk, strong fundamentals and defensive characteristics.\n",
            "   - FSLR: Low risk, potential for growth in renewable energy sector.\n",
            "   - FANG: Low risk, positive predicted return, and provides diversification.\n",
            "   - APH: Low risk, positive predicted return, and could offer sector diversification.\n",
            "   - CTAS: Low risk, positive predicted return, and provides diversification.\n",
            "   - MRK: Very Low risk, positive predicted return, and adds stability to the portfolio.\n",
            "   - WAB: Low risk, positive predicted return, and sector diversification.\n",
            "Fetching news for 10 top stocks...\n",
            "   - SYK (fetching...)\n",
            "   - SYK (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=SYK stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 3\n",
            "   - Found 3 articles for SYK\n",
            " ✓ Found 3 articles\n",
            "   - Analyzing sentiment for SYK... NEUTRAL\n",
            "     Sample: If You Invested $1000 In This Stock 10 Years Ago, You Would Have This Much Today\n",
            "\n",
            "   - WM (fetching...)\n",
            "   - WM (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=WM stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 17\n",
            "   - Found 5 articles for WM\n",
            " ✓ Found 5 articles\n",
            "   - Analyzing sentiment for WM... NEUTRAL\n",
            "     Sample: Stock Yards Bancorp (NASDAQ:SYBT) Stock Price Crosses Above 200-Day Moving Average – Should You Sell?\n",
            "\n",
            "   - ETN (fetching...)\n",
            "   - ETN (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=ETN stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 6\n",
            "   - Found 5 articles for ETN\n",
            " ✓ Found 5 articles\n",
            "   - Analyzing sentiment for ETN... NEUTRAL\n",
            "     Sample: Best Utility Stocks To Keep An Eye On – August 17th\n",
            "\n",
            "   - MDLZ (fetching...)\n",
            "   - MDLZ (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=MDLZ stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 2\n",
            "   - Found 2 articles for MDLZ\n",
            " ✓ Found 2 articles\n",
            "   - Analyzing sentiment for MDLZ... NEUTRAL\n",
            "     Sample: Promising Social Media Stocks To Follow Now – August 17th\n",
            "\n",
            "   - AIG (fetching...)\n",
            "   - AIG (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=AIG stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 2\n",
            "   - Found 2 articles for AIG\n",
            " ✓ Found 2 articles\n",
            "   - Analyzing sentiment for AIG... NEUTRAL\n",
            "     Sample: Warren Buffett has secretly invested $5 billion into a mystery stock — and the trail leads to this industrial giant\n",
            "\n",
            "   - GOOG (fetching...)\n",
            "   - GOOG (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=GOOG stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 14\n",
            "   - Found 5 articles for GOOG\n",
            " ✓ Found 5 articles\n",
            "   - Analyzing sentiment for GOOG... NEUTRAL\n",
            "     Sample: Bank of America suggests the era of the biggest stocks dominating markets 'may be done'\n",
            "\n",
            "   - MSFT (fetching...)\n",
            "   - MSFT (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=MSFT stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 113\n",
            "   - Found 5 articles for MSFT\n",
            " ✓ Found 5 articles\n",
            "   - Analyzing sentiment for MSFT... NEUTRAL\n",
            "     Sample: Intel stock surges 10% as SoftBank takes $2 billion stake in ailing chip company\n",
            "\n",
            "   - HII (fetching...)\n",
            "   - HII (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=HII stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 3\n",
            "   - Found 3 articles for HII\n",
            " ✓ Found 3 articles\n",
            "   - Analyzing sentiment for HII... NEUTRAL\n",
            "     Sample: Equities Analysts Offer Predictions for HII FY2025 Earnings\n",
            "\n",
            "   - ABT (fetching...)\n",
            "   - ABT (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=ABT stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 4\n",
            "   - Found 4 articles for ABT\n",
            " ✓ Found 4 articles\n",
            "   - Analyzing sentiment for ABT... NEUTRAL\n",
            "     Sample: Abbott Laboratories (NYSE:ABT) Stock Acquired Rep. Lisa C. McClain\n",
            "\n",
            "   - NWS (fetching...)\n",
            "   - NWS (fetching news...)\n",
            "   - API URL: https://newsapi.org/v2/everything?q=NWS stock&from=2025-08-13&to=2025-08-20&language=en&sortBy=publishedAt...\n",
            "   - API Response Status: 200\n",
            "   - Total Results: 12\n",
            "   - Found 5 articles for NWS\n",
            " ✓ Found 5 articles\n",
            "   - Analyzing sentiment for NWS... NEUTRAL\n",
            "     Sample: Millions to Be Hit by Massive Waves Across Three States\n",
            "\n",
            "News Collection Summary:\n",
            "   - SYK: 3 articles, NEUTRAL sentiment\n",
            "   - WM: 5 articles, NEUTRAL sentiment\n",
            "   - ETN: 5 articles, NEUTRAL sentiment\n",
            "   - MDLZ: 2 articles, NEUTRAL sentiment\n",
            "   - AIG: 2 articles, NEUTRAL sentiment\n",
            "   - GOOG: 5 articles, NEUTRAL sentiment\n",
            "   - MSFT: 5 articles, NEUTRAL sentiment\n",
            "   - HII: 3 articles, NEUTRAL sentiment\n",
            "   - ABT: 4 articles, NEUTRAL sentiment\n",
            "   - NWS: 5 articles, NEUTRAL sentiment\n",
            "Analyzing news sentiment and refining stock selection...\n",
            "Analysis complete. Creating portfolio...\n",
            "Portfolio Generation Attempt 1/5\n",
            "Portfolio recommendation received.\n",
            "Recommended Portfolio:\n",
            "NVDA: 30.0%\n",
            "MSFT: 25.0%\n",
            "AAPL: 20.0%\n",
            "AMZN: 15.0%\n",
            "GOOGL: 10.0%\n",
            "Strategy: Given the user's young age and high-risk tolerance, this portfolio leans towards growth stocks within the S&P 500. All five companies are dominant players with strong financials. The lack of negative news sentiment across the board allows for comfortable allocation.  The largest allocation to NVDA reflects its significant growth potential, while MSFT, AAPL, AMZN, and GOOGL offer stability and continued growth. Even with strong fundamentals, negative news could quickly change the outlook for any of these, so consistent monitoring is still required.\n",
            "1.0\n",
            "Ollama API 연결에 실패했습니다: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
            "{\"result\": {\"NVDA\": [0.3, 163.37, 0.0779], \"MSFT\": [0.25, 469.29, 0.0407], \"AAPL\": [0.2, 231.86, 0.0363], \"AMZN\": [0.15, 227.93, 0.0301], \"GOOGL\": [0.1, 200.51, 0.056]}, \"result2\": {\"NVDA\": [{\"y\": 148.23, \"ds\": \"2025-07-09 00:00:00\"}, {\"y\": 149.71, \"ds\": \"2025-07-10 00:00:00\"}, {\"y\": 150.31, \"ds\": \"2025-07-11 00:00:00\"}, {\"y\": 142.29, \"ds\": \"2025-07-14 00:00:00\"}, {\"y\": 141.73, \"ds\": \"2025-07-15 00:00:00\"}, {\"y\": 156.94, \"ds\": \"2025-07-16 00:00:00\"}, {\"y\": 139.69, \"ds\": \"2025-07-17 00:00:00\"}, {\"y\": 138.56, \"ds\": \"2025-07-18 00:00:00\"}, {\"y\": 146.5, \"ds\": \"2025-07-21 00:00:00\"}, {\"y\": 138.26, \"ds\": \"2025-07-22 00:00:00\"}, {\"y\": 159.22, \"ds\": \"2025-07-23 00:00:00\"}, {\"y\": 150.38, \"ds\": \"2025-07-24 00:00:00\"}, {\"y\": 163.37, \"ds\": \"2025-07-25 00:00:00\"}, {\"y\": 151.69, \"ds\": \"2025-07-28 00:00:00\"}, {\"y\": 148.01, \"ds\": \"2025-07-29 00:00:00\"}, {\"y\": 141.81, \"ds\": \"2025-07-30 00:00:00\"}, {\"y\": 136.8, \"ds\": \"2025-07-31 00:00:00\"}, {\"y\": 139.98, \"ds\": \"2025-08-01 00:00:00\"}, {\"y\": 125.17, \"ds\": \"2025-08-04 00:00:00\"}, {\"y\": 137.04, \"ds\": \"2025-08-05 00:00:00\"}, {\"y\": 152.84, \"ds\": \"2025-08-06 00:00:00\"}, {\"y\": 136.08, \"ds\": \"2025-08-07 00:00:00\"}], \"MSFT\": [{\"y\": 440.3, \"ds\": \"2025-07-09 00:00:00\"}, {\"y\": 450.24, \"ds\": \"2025-07-10 00:00:00\"}, {\"y\": 432.65, \"ds\": \"2025-07-11 00:00:00\"}, {\"y\": 442.06, \"ds\": \"2025-07-14 00:00:00\"}, {\"y\": 434.17, \"ds\": \"2025-07-15 00:00:00\"}, {\"y\": 466.67, \"ds\": \"2025-07-16 00:00:00\"}, {\"y\": 449.8, \"ds\": \"2025-07-17 00:00:00\"}, {\"y\": 438.08, \"ds\": \"2025-07-18 00:00:00\"}, {\"y\": 448.26, \"ds\": \"2025-07-21 00:00:00\"}, {\"y\": 422.3, \"ds\": \"2025-07-22 00:00:00\"}, {\"y\": 450.64, \"ds\": \"2025-07-23 00:00:00\"}, {\"y\": 460.5, \"ds\": \"2025-07-24 00:00:00\"}, {\"y\": 460.56, \"ds\": \"2025-07-25 00:00:00\"}, {\"y\": 449.36, \"ds\": \"2025-07-28 00:00:00\"}, {\"y\": 445.66, \"ds\": \"2025-07-29 00:00:00\"}, {\"y\": 433.56, \"ds\": \"2025-07-30 00:00:00\"}, {\"y\": 430.32, \"ds\": \"2025-07-31 00:00:00\"}, {\"y\": 421.1, \"ds\": \"2025-08-01 00:00:00\"}, {\"y\": 417.47, \"ds\": \"2025-08-04 00:00:00\"}, {\"y\": 454.86, \"ds\": \"2025-08-05 00:00:00\"}, {\"y\": 469.29, \"ds\": \"2025-08-06 00:00:00\"}, {\"y\": 444.37, \"ds\": \"2025-08-07 00:00:00\"}], \"AMZN\": [{\"y\": 222.69, \"ds\": \"2025-07-09 00:00:00\"}, {\"y\": 212.75, \"ds\": \"2025-07-10 00:00:00\"}, {\"y\": 218.38, \"ds\": \"2025-07-11 00:00:00\"}, {\"y\": 214.37, \"ds\": \"2025-07-14 00:00:00\"}, {\"y\": 214.08, \"ds\": \"2025-07-15 00:00:00\"}, {\"y\": 218.09, \"ds\": \"2025-07-16 00:00:00\"}, {\"y\": 211.96, \"ds\": \"2025-07-17 00:00:00\"}, {\"y\": 220.28, \"ds\": \"2025-07-18 00:00:00\"}, {\"y\": 223.35, \"ds\": \"2025-07-21 00:00:00\"}, {\"y\": 221.25, \"ds\": \"2025-07-22 00:00:00\"}, {\"y\": 219.91, \"ds\": \"2025-07-23 00:00:00\"}, {\"y\": 223.24, \"ds\": \"2025-07-24 00:00:00\"}, {\"y\": 215.77, \"ds\": \"2025-07-25 00:00:00\"}, {\"y\": 219.42, \"ds\": \"2025-07-28 00:00:00\"}, {\"y\": 216.11, \"ds\": \"2025-07-29 00:00:00\"}, {\"y\": 222.73, \"ds\": \"2025-07-30 00:00:00\"}, {\"y\": 216.09, \"ds\": \"2025-07-31 00:00:00\"}, {\"y\": 215.12, \"ds\": \"2025-08-01 00:00:00\"}, {\"y\": 223.02, \"ds\": \"2025-08-04 00:00:00\"}, {\"y\": 216.35, \"ds\": \"2025-08-05 00:00:00\"}, {\"y\": 227.93, \"ds\": \"2025-08-06 00:00:00\"}, {\"y\": 214.88, \"ds\": \"2025-08-07 00:00:00\"}], \"GOOGL\": [{\"y\": 182.48, \"ds\": \"2025-07-09 00:00:00\"}, {\"y\": 164.61, \"ds\": \"2025-07-10 00:00:00\"}, {\"y\": 175.68, \"ds\": \"2025-07-11 00:00:00\"}, {\"y\": 178.38, \"ds\": \"2025-07-14 00:00:00\"}, {\"y\": 183.65, \"ds\": \"2025-07-15 00:00:00\"}, {\"y\": 177.48, \"ds\": \"2025-07-16 00:00:00\"}, {\"y\": 185.61, \"ds\": \"2025-07-17 00:00:00\"}, {\"y\": 189.52, \"ds\": \"2025-07-18 00:00:00\"}, {\"y\": 181.87, \"ds\": \"2025-07-21 00:00:00\"}, {\"y\": 182.32, \"ds\": \"2025-07-22 00:00:00\"}, {\"y\": 179.55, \"ds\": \"2025-07-23 00:00:00\"}, {\"y\": 191.5, \"ds\": \"2025-07-24 00:00:00\"}, {\"y\": 174.94, \"ds\": \"2025-07-25 00:00:00\"}, {\"y\": 184.17, \"ds\": \"2025-07-28 00:00:00\"}, {\"y\": 190.77, \"ds\": \"2025-07-29 00:00:00\"}, {\"y\": 173.87, \"ds\": \"2025-07-30 00:00:00\"}, {\"y\": 178.74, \"ds\": \"2025-07-31 00:00:00\"}, {\"y\": 180.09, \"ds\": \"2025-08-01 00:00:00\"}, {\"y\": 168.81, \"ds\": \"2025-08-04 00:00:00\"}, {\"y\": 187.04, \"ds\": \"2025-08-05 00:00:00\"}, {\"y\": 193.94, \"ds\": \"2025-08-06 00:00:00\"}, {\"y\": 200.51, \"ds\": \"2025-08-07 00:00:00\"}], \"AAPL\": [{\"y\": 214.94, \"ds\": \"2025-07-09 00:00:00\"}, {\"y\": 208.68, \"ds\": \"2025-07-10 00:00:00\"}, {\"y\": 213.69, \"ds\": \"2025-07-11 00:00:00\"}, {\"y\": 210.38, \"ds\": \"2025-07-14 00:00:00\"}, {\"y\": 212.78, \"ds\": \"2025-07-15 00:00:00\"}, {\"y\": 210.89, \"ds\": \"2025-07-16 00:00:00\"}, {\"y\": 212.43, \"ds\": \"2025-07-17 00:00:00\"}, {\"y\": 222.02, \"ds\": \"2025-07-18 00:00:00\"}, {\"y\": 219.21, \"ds\": \"2025-07-21 00:00:00\"}, {\"y\": 227.17, \"ds\": \"2025-07-22 00:00:00\"}, {\"y\": 213.62, \"ds\": \"2025-07-23 00:00:00\"}, {\"y\": 212.96, \"ds\": \"2025-07-24 00:00:00\"}, {\"y\": 223.54, \"ds\": \"2025-07-25 00:00:00\"}, {\"y\": 231.86, \"ds\": \"2025-07-28 00:00:00\"}, {\"y\": 216.0, \"ds\": \"2025-07-29 00:00:00\"}, {\"y\": 206.58, \"ds\": \"2025-07-30 00:00:00\"}, {\"y\": 212.68, \"ds\": \"2025-07-31 00:00:00\"}, {\"y\": 220.17, \"ds\": \"2025-08-01 00:00:00\"}, {\"y\": 219.39, \"ds\": \"2025-08-04 00:00:00\"}, {\"y\": 230.25, \"ds\": \"2025-08-05 00:00:00\"}, {\"y\": 222.07, \"ds\": \"2025-08-06 00:00:00\"}, {\"y\": 230.44, \"ds\": \"2025-08-07 00:00:00\"}]}, \"result3\": [{\"y\": 100.0, \"ds\": \"2025-07-09 00:00:00\"}, {\"y\": 98.63261, \"ds\": \"2025-07-10 00:00:00\"}, {\"y\": 99.20734, \"ds\": \"2025-07-11 00:00:00\"}, {\"y\": 97.68834, \"ds\": \"2025-07-14 00:00:00\"}, {\"y\": 97.61959, \"ds\": \"2025-07-15 00:00:00\"}, {\"y\": 102.29938, \"ds\": \"2025-07-16 00:00:00\"}, {\"y\": 98.02623, \"ds\": \"2025-07-17 00:00:00\"}, {\"y\": 98.79911, \"ds\": \"2025-07-18 00:00:00\"}, {\"y\": 100.51018, \"ds\": \"2025-07-21 00:00:00\"}, {\"y\": 97.99239, \"ds\": \"2025-07-22 00:00:00\"}, {\"y\": 102.3407, \"ds\": \"2025-07-23 00:00:00\"}, {\"y\": 101.92919, \"ds\": \"2025-07-24 00:00:00\"}, {\"y\": 104.13542, \"ds\": \"2025-07-25 00:00:00\"}, {\"y\": 102.66143, \"ds\": \"2025-07-28 00:00:00\"}, {\"y\": 100.36952, \"ds\": \"2025-07-29 00:00:00\"}, {\"y\": 97.07094, \"ds\": \"2025-07-30 00:00:00\"}, {\"y\": 96.26023, \"ds\": \"2025-07-31 00:00:00\"}, {\"y\": 97.0859, \"ds\": \"2025-08-01 00:00:00\"}, {\"y\": 93.72383, \"ds\": \"2025-08-04 00:00:00\"}, {\"y\": 99.80941, \"ds\": \"2025-08-05 00:00:00\"}, {\"y\": 104.22346, \"ds\": \"2025-08-06 00:00:00\"}, {\"y\": 99.67632, \"ds\": \"2025-08-07 00:00:00\"}], \"result4\": \"Given the user's young age and high-risk tolerance, this portfolio leans towards growth stocks within the S&P 500. All five companies are dominant players with strong financials. The lack of negative news sentiment across the board allows for comfortable allocation.  The largest allocation to NVDA reflects its significant growth potential, while MSFT, AAPL, AMZN, and GOOGL offer stability and continued growth. Even with strong fundamentals, negative news could quickly change the outlook for any of these, so consistent monitoring is still required.\"}\n"
          ]
        }
      ]
    }
  ]
}